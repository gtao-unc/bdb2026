{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d59de1b",
   "metadata": {},
   "source": [
    "# End-to-End Big Data Bowl Heliocentricity Transformer\n",
    "\n",
    "This notebook provides a complete pipeline for:\n",
    "1. **Data Processing**: Load and transform raw CSV data into ML-ready format\n",
    "2. **Caching**: Save/load processed tensors to avoid reprocessing\n",
    "3. **Model Training**: Train the Heliocentricity Transformer with CVAE\n",
    "4. **Evaluation**: Evaluate predictions with metadata tracking\n",
    "5. **Heliocentricity**: Calculate Heliocentricity scores with play/player cross-referencing\n",
    "\n",
    "## Key Features\n",
    "- **Automatic caching**: Processed data saved to `dataset/processed/processed_data.pt`\n",
    "- **Metadata tracking**: Every prediction linked to game_id, play_id, and player_ids\n",
    "- **Pretrained weights**: Model weights saved to `dataset/pretrained/best_heliocentricity_model.pt`\n",
    "- **Cross-referencing**: Easy lookup of predictions by play and player\n",
    "\n",
    "## Notebook Structure\n",
    "1. Imports and hyperparameters\n",
    "2. Data preprocessing functions\n",
    "3. Model architecture (HeliocentricityTransformer)\n",
    "4. Loss and inference functions\n",
    "5. Custom dataset with padding and metadata\n",
    "6. Data loading (with caching)\n",
    "7. Training function\n",
    "8. Evaluation function (with metadata)\n",
    "9. Training execution\n",
    "10. Evaluation execution\n",
    "11. Heliocentricity calculation utilities\n",
    "12. Heliocentricity computation and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2088910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === End-to-End Big Data Bowl Heliocentricity Transformer ===\n",
    "# This notebook processes raw data, trains a model, and evaluates predictions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "# Data dimensions from Big Data Bowl\n",
    "T_HIST = 25         # Number of historical frames (max in dataset)\n",
    "T_PRED = 25         # Number of frames to predict (max in dataset)\n",
    "N_AGENTS = 9        # Actual number of agents per frame in data\n",
    "D_AGENT = 33        # Agent features: player_height, player_weight, s, a, dir, o, x_rel, y_rel + one-hot encoded position/side/role\n",
    "D_GLOBAL = 18       # Global features: down, yards_to_go + one-hot encoded dropback_type, team_coverage_type\n",
    "\n",
    "# Model architecture hyperparameters\n",
    "D_MODEL = 128       # Transformer Embedding Dimension\n",
    "D_LATENT = 32       # Latent variable Z dimension\n",
    "N_HEADS = 8         # Transformer Heads\n",
    "N_LAYERS = 3        # Transformer Encoder Layers\n",
    "KL_BETA = 0.01      # KL Loss Weight (needs tuning/annealing)\n",
    "\n",
    "# Training hyperparameters\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# File paths\n",
    "PROCESSED_DATA_PATH = Path('dataset/processed/processed_data.pt')\n",
    "PRETRAINED_WEIGHTS_PATH = Path('dataset/pretrained/best_heliocentricity_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87a2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Preprocessing Functions ===\n",
    "\n",
    "def standardize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a direction-invariant view of all plays.\n",
    "    \n",
    "    Returns a new DataFrame where:\n",
    "    - x_rel=0 is at the line of scrimmage (offense behind at negative x_rel, defense ahead at positive x_rel)\n",
    "    - All plays show offense driving toward increasing x (left to right / bottom to top)\n",
    "    - 'left' plays are flipped since they drive toward decreasing x\n",
    "    - Orientation and direction angles are properly adjusted\n",
    "    \n",
    "    Original DataFrame is not modified.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original\n",
    "    df_rel = df.copy()\n",
    "    \n",
    "    # Determine which plays need flipping\n",
    "    is_left = df_rel['play_direction'] == 'left'\n",
    "    \n",
    "    # For left plays, flip x coordinates (mirror horizontally)\n",
    "    df_rel.loc[is_left, 'x'] = 120 - df_rel.loc[is_left, 'x']\n",
    "    if 'ball_land_x' in df_rel.columns:\n",
    "        df_rel.loc[is_left, 'ball_land_x'] = 120 - df_rel.loc[is_left, 'ball_land_x']\n",
    "    \n",
    "    # For left plays, flip y coordinates (mirror vertically)\n",
    "    df_rel.loc[is_left, 'y'] = 53.3 - df_rel.loc[is_left, 'y']\n",
    "    if 'ball_land_y' in df_rel.columns:\n",
    "        df_rel.loc[is_left, 'ball_land_y'] = 53.3 - df_rel.loc[is_left, 'ball_land_y']\n",
    "    \n",
    "    # For left plays, flip orientation and direction angles\n",
    "    df_rel.loc[is_left, 'o'] = df_rel.loc[is_left, 'o'] - 180\n",
    "    df_rel.loc[is_left, 'dir'] = df_rel.loc[is_left, 'dir'] - 180\n",
    "    \n",
    "    # Normalize angles to [0, 360) range\n",
    "    df_rel.loc[is_left, 'o'] = df_rel.loc[is_left, 'o'] % 360\n",
    "    df_rel.loc[is_left, 'dir'] = df_rel.loc[is_left, 'dir'] % 360\n",
    "    \n",
    "    # Flip the absolute_yardline_number for left plays\n",
    "    df_rel.loc[is_left, 'absolute_yardline_number'] = 120 - df_rel.loc[is_left, 'absolute_yardline_number']\n",
    "    \n",
    "    # Make x relative to line of scrimmage (LOS at x=0)\n",
    "    df_rel['x_rel'] = df_rel['x'] - df_rel['absolute_yardline_number']\n",
    "    if 'ball_land_x' in df_rel.columns:\n",
    "        df_rel['ball_land_x_rel'] = df_rel['ball_land_x'] - df_rel['absolute_yardline_number']\n",
    "    \n",
    "    # Make y relative to center of field\n",
    "    df_rel['y_rel'] = df_rel['y'] - 26.65\n",
    "    if 'ball_land_y' in df_rel.columns:\n",
    "        df_rel['ball_land_y_rel'] = df_rel['ball_land_y'] - 26.65\n",
    "    \n",
    "    # Add distance to ball landing spot\n",
    "    if 'ball_land_x' in df_rel.columns and 'ball_land_y' in df_rel.columns:\n",
    "        df_rel['dist_to_ball'] = np.sqrt(\n",
    "            (df_rel['x'] - df_rel['ball_land_x'])**2 + \n",
    "            (df_rel['y'] - df_rel['ball_land_y'])**2\n",
    "        )\n",
    "    \n",
    "    return df_rel\n",
    "\n",
    "\n",
    "def height_to_inches(height_str):\n",
    "    \"\"\"Convert height string like '6-2' to inches (74)\"\"\"\n",
    "    if pd.isna(height_str):\n",
    "        return None\n",
    "    feet, inches = height_str.split('-')\n",
    "    return int(feet) * 12 + int(inches)\n",
    "\n",
    "\n",
    "def process_raw_data():\n",
    "    \"\"\"\n",
    "    Process raw CSV data into PyTorch tensors with play/player metadata.\n",
    "    Returns dictionary with tensors and metadata for cross-referencing predictions.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PROCESSING RAW DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Load and concatenate all input files\n",
    "    train_path = Path('dataset/train')\n",
    "    input_files = sorted(train_path.glob('input*.csv'))\n",
    "    \n",
    "    print(f\"\\nLoading {len(input_files)} input files...\")\n",
    "    dfs = []\n",
    "    for file in input_files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    all_weeks = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Total rows: {len(all_weeks):,}\")\n",
    "    \n",
    "    # 2. Standardize coordinates\n",
    "    print(\"\\nStandardizing coordinates...\")\n",
    "    all_weeks_std = standardize(all_weeks)\n",
    "    \n",
    "    # 3. Filter features (keep what we need after standardization)\n",
    "    play_features = [\n",
    "        'game_id', 'play_id', 'frame_id', 'nfl_id', 'player_height', 'player_weight',\n",
    "        'player_position', 'player_side', 'player_role', 's', 'a', 'dir', 'o',\n",
    "        'x_rel', 'y_rel', 'ball_land_x_rel', 'ball_land_y_rel'\n",
    "    ]\n",
    "    all_weeks_std = all_weeks_std.filter(play_features)\n",
    "    \n",
    "    # 4. Merge with supplementary data\n",
    "    print(\"Merging supplementary data...\")\n",
    "    supp = pd.read_csv('dataset/supplementary_data.csv')\n",
    "    supp_features = ['game_id', 'play_id', 'down', 'yards_to_go', 'dropback_type', 'team_coverage_type']\n",
    "    supp = supp.filter(supp_features)\n",
    "    \n",
    "    merged = pd.merge(left=all_weeks_std, right=supp, how='left', on=['game_id', 'play_id'])\n",
    "    \n",
    "    # 5. Convert height to inches and preserve player_side before encoding\n",
    "    print(\"One-hot encoding categorical features...\")\n",
    "    merged['player_height'] = merged['player_height'].apply(height_to_inches)\n",
    "    \n",
    "    # Preserve player_side for metadata before one-hot encoding\n",
    "    player_side_original = merged['player_side'].copy()\n",
    "    \n",
    "    categorical_cols = merged.select_dtypes(include=['object']).columns.tolist()\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_array = encoder.fit_transform(merged[categorical_cols])\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoded_feature_names, index=merged.index)\n",
    "    \n",
    "    merged_encoded = pd.concat([merged.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "    # Add back the original player_side for metadata extraction\n",
    "    merged_encoded['player_side_original'] = player_side_original\n",
    "    print(f\"Encoded shape: {merged_encoded.shape}\")\n",
    "    \n",
    "    # 6. Transform to ML format with metadata tracking\n",
    "    print(\"\\nTransforming to ML format...\")\n",
    "    grouped = merged_encoded.groupby(['game_id', 'play_id'])\n",
    "    \n",
    "    agent_feature_cols = ['player_height', 'player_weight', 's', 'a', 'dir', 'o', \n",
    "                          'x_rel', 'y_rel'] + [col for col in merged_encoded.columns \n",
    "                                                if (col.startswith('player_position_') or \n",
    "                                                    col.startswith('player_side_') or \n",
    "                                                    col.startswith('player_role_')) and \n",
    "                                                   col != 'player_side_original']\n",
    "    \n",
    "    global_feature_cols = ['down', 'yards_to_go'] + [col for col in merged_encoded.columns \n",
    "                                                       if col.startswith('dropback_type_') or \n",
    "                                                       col.startswith('team_coverage_type_')]\n",
    "    \n",
    "    trajectory_cols = ['x_rel', 'y_rel']\n",
    "    \n",
    "    historical_agent_features = []\n",
    "    global_context_features = []\n",
    "    ground_truth_trajectories = []\n",
    "    play_metadata = []  # Store game_id, play_id, player mapping\n",
    "    \n",
    "    for (game_id, play_id), play_data in grouped:\n",
    "        play_data = play_data.sort_values('frame_id')\n",
    "        frames = play_data['frame_id'].unique()\n",
    "        \n",
    "        if len(frames) < 2:\n",
    "            continue\n",
    "        \n",
    "        frame_data = []\n",
    "        ground_truth_data = []\n",
    "        player_ids = None\n",
    "        player_sides = None\n",
    "        \n",
    "        for i in range(len(frames) - 1):\n",
    "            current_frame = frames[i]\n",
    "            next_frame = frames[i + 1]\n",
    "            \n",
    "            current_frame_players = play_data[play_data['frame_id'] == current_frame].sort_values('nfl_id')\n",
    "            next_frame_players = play_data[play_data['frame_id'] == next_frame].sort_values('nfl_id')\n",
    "            \n",
    "            # Store player IDs and sides from first frame\n",
    "            if player_ids is None:\n",
    "                player_ids = current_frame_players['nfl_id'].astype(int).values\n",
    "                # Binary encode player_side: 0 for offense, 1 for defense\n",
    "                player_sides = (current_frame_players['player_side_original'] == 'defense').astype(int).values\n",
    "            \n",
    "            agent_features = current_frame_players[agent_feature_cols].values\n",
    "            frame_data.append(agent_features)\n",
    "            \n",
    "            next_positions = next_frame_players[trajectory_cols].values\n",
    "            ground_truth_data.append(next_positions)\n",
    "        \n",
    "        historical_agent_features.append(np.array(frame_data))\n",
    "        ground_truth_trajectories.append(np.array(ground_truth_data))\n",
    "        \n",
    "        global_features = play_data[global_feature_cols].iloc[0].values\n",
    "        global_context_features.append(global_features)\n",
    "        \n",
    "        # Store metadata for cross-referencing\n",
    "        play_metadata.append({\n",
    "            'game_id': int(game_id),\n",
    "            'play_id': int(play_id),\n",
    "            'player_ids': player_ids.tolist(),  # Convert to list for JSON compatibility\n",
    "            'player_sides': player_sides.tolist(),  # Binary encoded: 0=offense, 1=defense\n",
    "            'n_frames': len(frame_data),\n",
    "            'n_agents': len(player_ids)\n",
    "        })\n",
    "    \n",
    "    print(f\"Processed {len(historical_agent_features)} plays\")\n",
    "    \n",
    "    # 7. Convert to tensors\n",
    "    print(\"\\nConverting to PyTorch tensors...\")\n",
    "    print(f\"DEBUG: historical_agent_features type: {type(historical_agent_features)}\")\n",
    "    print(f\"DEBUG: First element type: {type(historical_agent_features[0])}\")\n",
    "    print(f\"DEBUG: First element dtype: {historical_agent_features[0].dtype}\")\n",
    "    print(f\"DEBUG: First element shape: {historical_agent_features[0].shape}\")\n",
    "    print(f\"DEBUG: Sample values from first element:\\n{historical_agent_features[0][0, 0, :]}\")\n",
    "    \n",
    "    historical_agent_features_tensors = [torch.tensor(arr, dtype=torch.float32) for arr in historical_agent_features]\n",
    "    ground_truth_trajectories_tensors = [torch.tensor(arr, dtype=torch.float32) for arr in ground_truth_trajectories]\n",
    "    global_context_features_tensor = torch.tensor(np.array(global_context_features), dtype=torch.float32)\n",
    "    \n",
    "    # 8. Save to disk\n",
    "    save_path = Path('dataset/processed')\n",
    "    save_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    torch.save({\n",
    "        'historical_agent_features': historical_agent_features_tensors,\n",
    "        'ground_truth_trajectories': ground_truth_trajectories_tensors,\n",
    "        'global_context_features': global_context_features_tensor,\n",
    "        'play_metadata': play_metadata  # Add metadata for cross-referencing\n",
    "    }, PROCESSED_DATA_PATH)\n",
    "    \n",
    "    print(f\"\\n✓ Saved processed data to {PROCESSED_DATA_PATH}\")\n",
    "    print(f\"  - {len(historical_agent_features_tensors)} plays\")\n",
    "    print(f\"  - {len(historical_agent_features_tensors)} plays with metadata\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return {\n",
    "        'historical_agent_features': historical_agent_features_tensors,\n",
    "        'ground_truth_trajectories': ground_truth_trajectories_tensors,\n",
    "        'global_context_features': global_context_features_tensor,\n",
    "        'play_metadata': play_metadata\n",
    "    }\n",
    "\n",
    "\n",
    "def load_or_process_data():\n",
    "    \"\"\"\n",
    "    Load processed data if it exists, otherwise process raw data.\n",
    "    \"\"\"\n",
    "    if PROCESSED_DATA_PATH.exists():\n",
    "        print(f\"✓ Loading cached data from {PROCESSED_DATA_PATH}\")\n",
    "        loaded_data = torch.load(PROCESSED_DATA_PATH)\n",
    "        print(f\"  Loaded {len(loaded_data['historical_agent_features'])} plays\")\n",
    "        return loaded_data\n",
    "    else:\n",
    "        print(f\"✗ Cached data not found at {PROCESSED_DATA_PATH}\")\n",
    "        print(\"  Processing raw data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589959a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeliocentricityTransformer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Unpack kwargs for clarity\n",
    "        self.T_HIST, self.T_PRED, self.N_AGENTS = kwargs['T_HIST'], kwargs['T_PRED'], kwargs['N_AGENTS']\n",
    "        self.D_AGENT, self.D_GLOBAL, self.D_MODEL = kwargs['D_AGENT'], kwargs['D_GLOBAL'], kwargs['D_MODEL']\n",
    "        self.D_LATENT, self.N_HEADS, self.N_LAYERS = kwargs['D_LATENT'], kwargs['N_HEADS'], kwargs['N_LAYERS']\n",
    "        self.KL_BETA = kwargs['KL_BETA']\n",
    "        \n",
    "        # --- 1. Initial Embedding Layers ---\n",
    "        self.agent_embed = nn.Linear(self.D_AGENT, self.D_MODEL)\n",
    "        self.global_embed = nn.Linear(self.D_GLOBAL, self.D_MODEL)\n",
    "        \n",
    "        # --- 2. Transformer Encoder (Core STT) ---\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.D_MODEL, \n",
    "            nhead=self.N_HEADS, \n",
    "            dim_feedforward=self.D_MODEL * 4, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=self.N_LAYERS)\n",
    "        \n",
    "        # --- 3. CVAE Heads (Prediction Heads from Context C) ---\n",
    "        # CAVE requires a context vector (C) for prior/recognition networks\n",
    "        \n",
    "        # CVAE: Prior Network (p(z|C)) -> outputs mu_prior, log_var_prior\n",
    "        self.mlp_prior = nn.Sequential(\n",
    "            nn.Linear(self.D_MODEL, self.D_MODEL),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.D_MODEL, 2 * self.D_LATENT)\n",
    "        )\n",
    "\n",
    "        # CVAE: Recognition Network (q(z|C, Y_truth)) -> outputs mu_rec, log_var_rec\n",
    "        # Input is C + flattened Y_truth (context + ground truth trajectory)\n",
    "        self.mlp_recognition = nn.Sequential(\n",
    "            nn.Linear(self.D_MODEL + self.T_PRED * self.N_AGENTS * 2, self.D_MODEL),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.D_MODEL, 2 * self.D_LATENT)\n",
    "        )\n",
    "\n",
    "        # --- 4. Decoder Head (Trajectory Generator) ---\n",
    "        # Input is C + Z. Output is the flattened trajectory (x, y coordinates)\n",
    "        self.mlp_decoder = nn.Sequential(\n",
    "            nn.Linear(self.D_MODEL + self.D_LATENT, self.D_MODEL * 2),\n",
    "            nn.ReLU(),\n",
    "            # Output shape: (Batch, T_PRED * N_AGENTS * 2)\n",
    "            nn.Linear(self.D_MODEL * 2, self.T_PRED * self.N_AGENTS * 2)\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        # Sampling Z = mu + sigma * epsilon\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, X_hist_agents, X_global, Y_truth=None):\n",
    "        B = X_hist_agents.size(0)\n",
    "        \n",
    "        # 1. Agent Embedding (Per-Frame)\n",
    "        # (B, T_hist, N_agents, D_agent) -> (B, T_hist, N_agents, D_MODEL)\n",
    "        agent_emb = self.agent_embed(X_hist_agents)\n",
    "        \n",
    "        # 2. Global CLS Token Embedding\n",
    "        # (B, D_global) -> (B, D_MODEL)\n",
    "        global_emb = self.global_embed(X_global)\n",
    "        # Expand for T_hist: (B, 1, 1, D_MODEL). Expand(T_hist) not needed as we use flatten below\n",
    "        \n",
    "        # 3. Prepare Sequence for Transformer\n",
    "        \n",
    "        # Create CLS Token for each time step in the historical sequence\n",
    "        # Shape: (B, T_hist, 1, D_MODEL)\n",
    "        cls_tokens = global_emb.unsqueeze(1).unsqueeze(1).expand(-1, self.T_HIST, -1, -1)\n",
    "        \n",
    "        # Concatenate CLS token to the front of each frame's set of agents\n",
    "        # Shape: (B, T_hist, N_agents + 1, D_MODEL)\n",
    "        input_sequence = torch.cat([cls_tokens, agent_emb], dim=2)\n",
    "        \n",
    "        # Flatten time and agent dimensions for Transformer input\n",
    "        # Shape: (B, T_hist * (N_agents + 1), D_MODEL)\n",
    "        flat_input = input_sequence.view(B, -1, self.D_MODEL)\n",
    "        \n",
    "        # Add Positional/Temporal Encoding here (Omitted)\n",
    "        \n",
    "        # 4. Transformer Encoding\n",
    "        # Encoded_Output: (B, T_hist * (N_agents + 1), D_MODEL)\n",
    "        encoded_output = self.transformer_encoder(flat_input)\n",
    "        \n",
    "        # 5. Extract Context Vector C from the first CLS token\n",
    "        # The first token is CLS at t=0. C should capture the full context.\n",
    "        # Context C: (B, D_MODEL)\n",
    "        C = encoded_output[:, 0, :]\n",
    "        \n",
    "        # --- CVAE Latent Space ---\n",
    "        # Prior Network: p(z|C)\n",
    "        mu_prior, log_var_prior = self.mlp_prior(C).chunk(2, dim=-1)\n",
    "\n",
    "        # Recognition Network: q(z|C, Y_truth) is only used during training\n",
    "        if Y_truth is not None:\n",
    "            # Flatten Y_truth: (B, T_pred * N_agents * 2)\n",
    "            Y_flat = Y_truth.view(B, -1)\n",
    "            rec_input = torch.cat([C, Y_flat], dim=-1)\n",
    "            mu_rec, log_var_rec = self.mlp_recognition(rec_input).chunk(2, dim=-1)\n",
    "            Z = self.reparameterize(mu_rec, log_var_rec)\n",
    "        else:\n",
    "            # Inference: Sample Z from the Prior distribution p(z|C)\n",
    "            # This is key for generating diverse, expected trajectories (E)\n",
    "            Z = self.reparameterize(mu_prior, log_var_prior)\n",
    "            mu_rec, log_var_rec = mu_prior, log_var_prior # Use prior stats for loss calc placeholder\n",
    "\n",
    "        # --- Decoder ---\n",
    "        # Input: [C, Z]\n",
    "        decoder_input = torch.cat([C, Z], dim=-1)\n",
    "        \n",
    "        # Output: (B, T_pred * N_agents * 2)\n",
    "        Y_pred_flat = self.mlp_decoder(decoder_input)\n",
    "        \n",
    "        # Reshape to (B, T_pred, N_agents, 2)\n",
    "        Y_pred = Y_pred_flat.view(B, self.T_PRED, self.N_AGENTS, 2)\n",
    "        \n",
    "        return Y_pred, mu_rec, log_var_rec, mu_prior, log_var_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7b44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(Y_pred, Y_truth, mu_rec, log_var_rec, mu_prior, log_var_prior, KL_BETA):\n",
    "    # 1. Reconstruction Loss (L_recon): RMSE on the predicted x, y coordinates\n",
    "    # We use MSE here for simplicity in PyTorch, but RMSE is the metric.\n",
    "    L_recon = F.mse_loss(Y_pred, Y_truth, reduction='sum') / Y_pred.size(0) # Mean over batch\n",
    "\n",
    "    # 2. KL Divergence Loss (L_KL): KL(q(z|C, Y) || p(z|C))\n",
    "    # Closed-form KL for Gaussian: 0.5 * sum(1 + log(sigma_prior^2) - log(sigma_rec^2) - (mu_rec - mu_prior)^2 / sigma_prior^2 - exp(log(sigma_rec^2)) / sigma_prior^2)\n",
    "    # Using torch.exp(log_var) = sigma^2\n",
    "    kl_loss = 0.5 * torch.sum(\n",
    "        log_var_prior - log_var_rec - 1 \n",
    "        + (torch.exp(log_var_rec) + (mu_rec - mu_prior).pow(2)) / torch.exp(log_var_prior)\n",
    "    ) / Y_pred.size(0)\n",
    "\n",
    "    # Total Loss (Weighted sum)\n",
    "    total_loss = L_recon + KL_BETA * kl_loss\n",
    "    return total_loss, L_recon.item(), kl_loss.item()\n",
    "\n",
    "# --- Heliocentricity Inference Function (E Generator) ---\n",
    "@torch.no_grad()\n",
    "def generate_expected_trajectories(model, X_hist_agents, X_global, K=10):\n",
    "    \"\"\"\n",
    "    Generates K diverse, plausible trajectories for the defense (E) \n",
    "    by sampling the latent space Z from the prior distribution.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    B = X_hist_agents.size(0)\n",
    "    \n",
    "    # Repeat inputs K times to batch the K samples\n",
    "    X_hist_agents_K = X_hist_agents.repeat_interleave(K, dim=0)\n",
    "    X_global_K = X_global.repeat_interleave(K, dim=0)\n",
    "\n",
    "    # Since Y_truth=None, Z is sampled from the prior p(z|C)\n",
    "    Y_pred_K, _, _, _, _ = model(X_hist_agents_K, X_global_K, Y_truth=None)\n",
    "    \n",
    "    # Reshape: (B * K, T_pred, N_agents, 2) -> (B, K, T_pred, N_agents, 2)\n",
    "    return Y_pred_K.view(B, K, model.T_PRED, model.N_AGENTS, 2)\n",
    "\n",
    "# Note: The final step of calculating Heliocentricity (H) based on \n",
    "# min separation distance (A vs E) is a NumPy/Pandas operation after this PyTorch step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7d27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Custom Dataset with Padding and Metadata Tracking ===\n",
    "\n",
    "class FootballDataset(Dataset):\n",
    "    \"\"\"Dataset with padding for variable-length sequences and metadata tracking.\"\"\"\n",
    "    \n",
    "    def __init__(self, hist_features, gt_trajectories, global_features, metadata, \n",
    "                 max_hist_len=None, max_pred_len=None, max_n_agents=None):\n",
    "        self.hist_features = hist_features\n",
    "        self.gt_trajectories = gt_trajectories\n",
    "        self.global_features = global_features\n",
    "        self.metadata = metadata  # Play/player metadata for cross-referencing\n",
    "        \n",
    "        # Determine max lengths if not provided\n",
    "        self.max_hist_len = max_hist_len or max(x.shape[0] for x in hist_features)\n",
    "        self.max_pred_len = max_pred_len or max(y.shape[0] for y in gt_trajectories)\n",
    "        self.max_n_agents = max_n_agents or max(x.shape[1] for x in hist_features)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hist_features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        hist = self.hist_features[idx]  # (T_hist_actual, N_agents_actual, D_agent)\n",
    "        gt = self.gt_trajectories[idx]  # (T_pred_actual, N_agents_actual, 2)\n",
    "        global_feat = self.global_features[idx]  # (D_global,)\n",
    "        meta = self.metadata[idx]  # Play metadata\n",
    "        \n",
    "        # Get actual lengths\n",
    "        hist_len = hist.shape[0]\n",
    "        pred_len = gt.shape[0]\n",
    "        n_agents = hist.shape[1]\n",
    "        \n",
    "        # Pad historical features to max_hist_len and max_n_agents\n",
    "        if hist_len < self.max_hist_len:\n",
    "            pad_hist_time = torch.zeros(self.max_hist_len - hist_len, hist.shape[1], hist.shape[2], dtype=hist.dtype)\n",
    "            hist = torch.cat([hist, pad_hist_time], dim=0)\n",
    "        else:\n",
    "            hist = hist[:self.max_hist_len]\n",
    "            hist_len = self.max_hist_len\n",
    "        \n",
    "        if n_agents < self.max_n_agents:\n",
    "            pad_hist_agents = torch.zeros(hist.shape[0], self.max_n_agents - n_agents, hist.shape[2], dtype=hist.dtype)\n",
    "            hist_padded = torch.cat([hist, pad_hist_agents], dim=1)\n",
    "        else:\n",
    "            hist_padded = hist[:, :self.max_n_agents, :]\n",
    "            n_agents = self.max_n_agents\n",
    "        \n",
    "        # Pad ground truth to max_pred_len and max_n_agents\n",
    "        if pred_len < self.max_pred_len:\n",
    "            pad_gt_time = torch.zeros(self.max_pred_len - pred_len, gt.shape[1], 2, dtype=gt.dtype)\n",
    "            gt = torch.cat([gt, pad_gt_time], dim=0)\n",
    "        else:\n",
    "            gt = gt[:self.max_pred_len]\n",
    "            pred_len = self.max_pred_len\n",
    "        \n",
    "        if gt.shape[1] < self.max_n_agents:\n",
    "            pad_gt_agents = torch.zeros(gt.shape[0], self.max_n_agents - gt.shape[1], 2, dtype=gt.dtype)\n",
    "            gt_padded = torch.cat([gt, pad_gt_agents], dim=1)\n",
    "        else:\n",
    "            gt_padded = gt[:, :self.max_n_agents, :]\n",
    "        \n",
    "        # Return data + metadata index for cross-referencing\n",
    "        return hist_padded, global_feat, gt_padded, hist_len, pred_len, idx\n",
    "    \n",
    "    def get_metadata(self, idx):\n",
    "        \"\"\"Get play/player metadata for a specific index.\"\"\"\n",
    "        return self.metadata[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46aa446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loading cached data from dataset/processed/processed_data.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/cfchh_0s3zv0_x826rm19h1r0000gn/T/ipykernel_9154/2587755749.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load(PROCESSED_DATA_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 14108 plays\n",
      "\n",
      "Global context shape: torch.Size([14108, 18])\n",
      "Sample play metadata: {'game_id': 2023090700, 'play_id': 101, 'player_ids': [43290, 44930, 46137, 52546, 53487, 53541, 53959, 54486, 54527], 'player_sides': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'n_frames': 25, 'n_agents': 9}\n",
      "\n",
      "Using device: cpu\n",
      "\n",
      "Dataset split: Train=11286, Test=2822\n",
      "Max hist length: 25, Max pred length: 25, Max agents: 9\n",
      "Model initialized with 865,602 parameters\n",
      "Model initialized with 865,602 parameters\n"
     ]
    }
   ],
   "source": [
    "# === Load or Process Data ===\n",
    "\n",
    "# Load cached data or process from scratch\n",
    "loaded_data = load_or_process_data()\n",
    "\n",
    "# Extract data and metadata\n",
    "historical_agent_features = loaded_data['historical_agent_features']\n",
    "ground_truth_trajectories = loaded_data['ground_truth_trajectories']\n",
    "global_context_features = loaded_data['global_context_features']\n",
    "play_metadata = loaded_data['play_metadata']\n",
    "\n",
    "print(f\"\\nGlobal context shape: {global_context_features.shape}\")\n",
    "print(f\"Sample play metadata: {play_metadata[0]}\")\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    'T_HIST': T_HIST, 'T_PRED': T_PRED, 'N_AGENTS': N_AGENTS, 'D_AGENT': D_AGENT, \n",
    "    'D_GLOBAL': D_GLOBAL, 'D_MODEL': D_MODEL, 'D_LATENT': D_LATENT, 'N_HEADS': N_HEADS, \n",
    "    'N_LAYERS': N_LAYERS, 'KL_BETA': KL_BETA\n",
    "}\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Create dataset with metadata\n",
    "dataset = FootballDataset(\n",
    "    historical_agent_features, \n",
    "    ground_truth_trajectories, \n",
    "    global_context_features,\n",
    "    play_metadata,\n",
    "    max_hist_len=model_config['T_HIST'],\n",
    "    max_pred_len=model_config['T_PRED'],\n",
    "    max_n_agents=model_config['N_AGENTS']\n",
    ")\n",
    "\n",
    "# Split into train and test sets (80/20)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "print(f\"\\nDataset split: Train={train_size}, Test={test_size}\")\n",
    "print(f\"Max hist length: {dataset.max_hist_len}, Max pred length: {dataset.max_pred_len}, Max agents: {dataset.max_n_agents}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize Model and Optimizer\n",
    "model = HeliocentricityTransformer(**model_config).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37835750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. The Training Loop with Masking ---\n",
    "\n",
    "def create_mask(lengths, max_len, device):\n",
    "    \"\"\"Create attention mask: True for valid positions, False for padding\"\"\"\n",
    "    batch_size = len(lengths)\n",
    "    mask = torch.arange(max_len, device=device).expand(batch_size, max_len) < lengths.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "def train_model(model, train_loader, optimizer, model_config, device, num_epochs=20):\n",
    "    \"\"\"\n",
    "    Train the Heliocentricity Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        model: The HeliocentricityTransformer model\n",
    "        train_loader: DataLoader for training data\n",
    "        optimizer: Optimizer for training\n",
    "        model_config: Dictionary with model configuration\n",
    "        device: Device to train on (cuda/cpu)\n",
    "        num_epochs: Number of epochs to train\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with training history\n",
    "    \"\"\"\n",
    "    print(f\"Starting training on {device}...\")\n",
    "    \n",
    "    history = {\n",
    "        'total_loss': [],\n",
    "        'recon_loss': [],\n",
    "        'kl_loss': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_kl_loss = 0\n",
    "        \n",
    "        for batch_idx, (X_agents, X_global, Y_truth, hist_lens, pred_lens, _) in enumerate(train_loader):\n",
    "            \n",
    "            # Move to device\n",
    "            X_agents = X_agents.to(device)\n",
    "            X_global = X_global.to(device)\n",
    "            Y_truth = Y_truth.to(device)\n",
    "            hist_lens = hist_lens.to(device)\n",
    "            pred_lens = pred_lens.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 1. Forward Pass\n",
    "            Y_pred, mu_rec, log_var_rec, mu_prior, log_var_prior = model(X_agents, X_global, Y_truth=Y_truth)\n",
    "            \n",
    "            # 2. Create mask for ground truth prediction loss\n",
    "            pred_mask = create_mask(pred_lens, model_config['T_PRED'], device)\n",
    "            pred_mask_expanded = pred_mask.unsqueeze(-1).unsqueeze(-1).expand_as(Y_pred)\n",
    "            \n",
    "            # Apply mask to predictions and ground truth\n",
    "            Y_pred_masked = Y_pred * pred_mask_expanded\n",
    "            Y_truth_masked = Y_truth * pred_mask_expanded\n",
    "            \n",
    "            # 3. Compute VAE Loss with masked outputs\n",
    "            L_recon = F.mse_loss(Y_pred_masked, Y_truth_masked, reduction='sum') / pred_lens.sum()\n",
    "            \n",
    "            kl_loss = 0.5 * torch.sum(\n",
    "                log_var_prior - log_var_rec - 1 \n",
    "                + (torch.exp(log_var_rec) + (mu_rec - mu_prior).pow(2)) / torch.exp(log_var_prior)\n",
    "            ) / X_agents.size(0)\n",
    "            \n",
    "            loss = L_recon + model_config['KL_BETA'] * kl_loss\n",
    "            \n",
    "            # 4. Backward Pass and Optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += L_recon.item()\n",
    "            total_kl_loss += kl_loss.item()\n",
    "            \n",
    "            # Print update every 100 batches\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"  Batch {batch_idx+1}/{len(train_loader)} | Total Loss: {total_loss / (batch_idx+1):.4f} | Recon: {total_recon_loss / (batch_idx+1):.4f} | KL: {total_kl_loss / (batch_idx+1):.4f}\")\n",
    "    \n",
    "        # --- End of Epoch ---\n",
    "        avg_epoch_loss = total_loss / len(train_loader)\n",
    "        avg_recon = total_recon_loss / len(train_loader)\n",
    "        avg_kl = total_kl_loss / len(train_loader)\n",
    "        \n",
    "        history['total_loss'].append(avg_epoch_loss)\n",
    "        history['recon_loss'].append(avg_recon)\n",
    "        history['kl_loss'].append(avg_kl)\n",
    "        \n",
    "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} Complete ---\")\n",
    "        print(f\"Average Total Loss: {avg_epoch_loss:.4f} | Recon: {avg_recon:.4f} | KL: {avg_kl:.4f}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5cfcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the saved model weights\n",
    "# model.load_state_dict(torch.load(\"best_heliocentricity_model.pt\"))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, data_loader, dataset, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model and return results with metadata for Heliocentricity calculation.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained HeliocentricityTransformer model\n",
    "        data_loader: DataLoader for evaluation data\n",
    "        dataset: The FootballDataset instance to retrieve metadata\n",
    "        device: Device to evaluate on (cuda/cpu)\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with predictions and metadata for each play\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_rmse = []\n",
    "    total_recon_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    \n",
    "    # Store data for final Heliocentricity calculation\n",
    "    results_for_H_calc = []\n",
    "\n",
    "    for batch_idx, (X_agents, X_global, Y_truth, hist_lens, pred_lens, indices) in enumerate(data_loader):\n",
    "            \n",
    "        # Move to device\n",
    "        X_agents = X_agents.to(device)\n",
    "        X_global = X_global.to(device)\n",
    "        Y_truth = Y_truth.to(device)\n",
    "        hist_lens = hist_lens.to(device)\n",
    "        pred_lens = pred_lens.to(device)\n",
    "\n",
    "        # 1. Deterministic Prediction (for Reconstruction Loss)\n",
    "        # Uses the recognition network q(z|C, Y_truth) which yields the best reconstruction\n",
    "        Y_pred, mu_rec, log_var_rec, mu_prior, log_var_prior = model(X_agents, X_global, Y_truth=Y_truth)\n",
    "        \n",
    "        # Calculate Loss components\n",
    "        loss, L_recon, L_KL = vae_loss(\n",
    "            Y_pred, Y_truth, \n",
    "            mu_rec, log_var_rec, mu_prior, log_var_prior, \n",
    "            model.KL_BETA\n",
    "        )\n",
    "        total_recon_loss += L_recon\n",
    "        total_kl_loss += L_KL\n",
    "\n",
    "        # 2. Calculate Root Mean Squared Error (RMSE) on the deterministic prediction\n",
    "        # Detach and convert to numpy for standard metric calculation\n",
    "        Y_pred_np = Y_pred.cpu().numpy()\n",
    "        Y_truth_np = Y_truth.cpu().numpy()\n",
    "        \n",
    "        # Calculate RMSE for each sample and average (Flattening all T_pred * N_agents * 2 dimensions)\n",
    "        sample_rmse = np.sqrt(mean_squared_error(Y_truth_np.reshape(-1, 1), Y_pred_np.reshape(-1, 1)))\n",
    "        total_rmse.append(sample_rmse)\n",
    "\n",
    "        # 3. Generate K Stochastic Predictions for Heliocentricity (E)\n",
    "        # This uses the prior network p(z|C) for diverse sampling\n",
    "        K = 10 # Number of samples per play\n",
    "        Y_pred_K = generate_expected_trajectories(model, X_agents, X_global, K=K).cpu().numpy()\n",
    "        \n",
    "        # 4. Store results with metadata for each play in batch\n",
    "        for i in range(Y_truth_np.shape[0]):\n",
    "            # Get the original dataset index for this sample\n",
    "            dataset_idx = indices[i].item()\n",
    "            metadata = dataset.get_metadata(dataset_idx)\n",
    "            \n",
    "            # Store all data needed for Heliocentricity calculation\n",
    "            results_for_H_calc.append({\n",
    "                'Y_truth': Y_truth_np[i],\n",
    "                'Y_pred': Y_pred_np[i],\n",
    "                'Y_pred_K': Y_pred_K[i],\n",
    "                'game_id': metadata['game_id'],\n",
    "                'play_id': metadata['play_id'],\n",
    "                'player_ids': metadata['player_ids'],\n",
    "                'player_sides': metadata['player_sides'],\n",
    "                'n_agents': metadata['n_agents'],\n",
    "                'star_idx': 4  # TODO: Identify actual star receiver from metadata\n",
    "            })\n",
    "\n",
    "        # Print update every 100 batches\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Batch {batch_idx+1}/{len(data_loader)}\")\n",
    "\n",
    "    avg_rmse = np.mean(total_rmse)\n",
    "    avg_recon = total_recon_loss / len(data_loader)\n",
    "    avg_kl = total_kl_loss / len(data_loader)\n",
    "    \n",
    "    print(f\"\\n--- Validation Results ---\")\n",
    "    print(f\"Avg Trajectory RMSE: {avg_rmse:.4f} meters\")\n",
    "    print(f\"Avg Reconstruction Loss: {avg_recon:.4f}\")\n",
    "    print(f\"Avg KL Divergence: {avg_kl:.4f}\")\n",
    "    \n",
    "    return results_for_H_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26748931-5208-439f-abbc-e3b20738884b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model from scratch:\n",
      "Starting training on cpu...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PRETRAINED_WGTS \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining model from scratch:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/pretrained/best_heliocentricity_model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[7], line 51\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, model_config, device, num_epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 1. Forward Pass\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m Y_pred, mu_rec, log_var_rec, mu_prior, log_var_prior \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_agents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_truth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_truth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 2. Create mask for ground truth prediction loss\u001b[39;00m\n\u001b[1;32m     54\u001b[0m pred_mask \u001b[38;5;241m=\u001b[39m create_mask(pred_lens, model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_PRED\u001b[39m\u001b[38;5;124m'\u001b[39m], device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[3], line 87\u001b[0m, in \u001b[0;36mHeliocentricityTransformer.forward\u001b[0;34m(self, X_hist_agents, X_global, Y_truth)\u001b[0m\n\u001b[1;32m     81\u001b[0m flat_input \u001b[38;5;241m=\u001b[39m input_sequence\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD_MODEL)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Add Positional/Temporal Encoding here (Omitted)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# 4. Transformer Encoding\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Encoded_Output: (B, T_hist * (N_agents + 1), D_MODEL)\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m encoded_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# 5. Extract Context Vector C from the first CLS token\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# The first token is CLS at t=0. C should capture the full context.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Context C: (B, D_MODEL)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m C \u001b[38;5;241m=\u001b[39m encoded_output[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:511\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    508\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 511\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    519\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:904\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    900\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m    903\u001b[0m         x\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     )\n\u001b[1;32m    906\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:918\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    913\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    917\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 918\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1343\u001b[0m         query,\n\u001b[1;32m   1344\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/functional.py:6278\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6275\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   6276\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 6278\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[1;32m   6280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6281\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   6282\u001b[0m     attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   6283\u001b[0m )\n\u001b[1;32m   6285\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PRETRAINED_WGTS = None #Path('dataset/pretrained/best_heliocentricity_model.pt')\n",
    "\n",
    "if PRETRAINED_WGTS is None:\n",
    "    print('Training model from scratch:')\n",
    "    train_model(model,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                model_config,\n",
    "                device,\n",
    "                num_epochs=NUM_EPOCHS)\n",
    "    torch.save(model.state_dict(), 'dataset/pretrained/best_heliocentricity_model.pt')\n",
    "else:\n",
    "    print('Loading model from pretrained weights:')\n",
    "    state_dict = torch.load(PRETRAINED_WGTS, map_location=device)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decea14-883c-42c4-8015-1b4f62bd2deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100/177\n",
      "\n",
      "--- Validation Results ---\n",
      "Avg Trajectory RMSE: 2.8821 meters\n",
      "Avg Reconstruction Loss: 14763.0471\n",
      "Avg KL Divergence: 608.6204\n"
     ]
    }
   ],
   "source": [
    "# === Evaluate Model ===\n",
    "results = evaluate_model(model, test_loader, dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Heliocentricity Calculation Utilities ===\n",
    "\n",
    "def min_separation_distance(receiver_coords, defense_coords):\n",
    "    \"\"\"\n",
    "    Calculate minimum separation distance between receiver and defense.\n",
    "    \n",
    "    Args:\n",
    "        receiver_coords: (T_pred, 2) - receiver trajectory\n",
    "        defense_coords: (T_pred, N_defenders, 2) - defense trajectories\n",
    "        \n",
    "    Returns:\n",
    "        (T_pred,) array of minimum distances at each timestep\n",
    "    \"\"\"\n",
    "    # Calculate distance from receiver to every defender at every frame\n",
    "    dist_to_defenders = np.linalg.norm(\n",
    "        receiver_coords[:, np.newaxis, :] - defense_coords, axis=2\n",
    "    )\n",
    "    \n",
    "    # Find the minimum separation at each frame\n",
    "    min_dist = np.min(dist_to_defenders, axis=1)\n",
    "    return min_dist\n",
    "\n",
    "\n",
    "def compute_heliocentricity(play_data):\n",
    "    \"\"\"\n",
    "    Compute Heliocentricity score for a single play WITH metadata tracking.\n",
    "    \n",
    "    Args:\n",
    "        play_data: Dictionary with:\n",
    "            - 'Y_truth': (T_pred, N_agents, 2) ground truth trajectories\n",
    "            - 'Y_pred_K': (K, T_pred, N_agents, 2) stochastic predictions\n",
    "            - 'star_idx': Index of the star receiver\n",
    "            - 'player_sides': Binary array (0=offense, 1=defense)\n",
    "            - 'game_id', 'play_id', 'player_ids': Metadata for cross-referencing\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with H_score, H_frame_diff, and metadata\n",
    "    \"\"\"\n",
    "    Y_truth = play_data['Y_truth']\n",
    "    Y_pred_K = play_data['Y_pred_K']\n",
    "    star_idx = play_data['star_idx']\n",
    "    player_sides = np.array(play_data['player_sides'])  # Binary encoded: 0=offense, 1=defense\n",
    "    \n",
    "    # Identify defensive players using binary encoding (1 = defense)\n",
    "    def_indices = np.where(player_sides == 1)[0]\n",
    "    \n",
    "    if len(def_indices) == 0:\n",
    "        # Fallback if no defense found: use all except star receiver\n",
    "        all_indices = np.arange(len(player_sides))\n",
    "        def_indices = all_indices[all_indices != star_idx]\n",
    "    \n",
    "    # Calculate Actual Attention (A)\n",
    "    actual_R_coords = Y_truth[:, star_idx, :]\n",
    "    actual_D_coords = Y_truth[:, def_indices, :]\n",
    "    A = min_separation_distance(actual_R_coords, actual_D_coords)\n",
    "    \n",
    "    # Calculate Expected Coverage (E)\n",
    "    E_K = []\n",
    "    for k in range(Y_pred_K.shape[0]):\n",
    "        predicted_D_coords = Y_pred_K[k, :, def_indices, :]\n",
    "        E_k = min_separation_distance(actual_R_coords, predicted_D_coords)\n",
    "        E_K.append(E_k)\n",
    "    \n",
    "    E_mean = np.mean(np.stack(E_K, axis=0), axis=0)\n",
    "    \n",
    "    # Calculate Heliocentricity (H = E - A)\n",
    "    H_frame_diff = E_mean - A\n",
    "    H_score = np.mean(H_frame_diff)\n",
    "    \n",
    "    return {\n",
    "        'H_score': H_score,\n",
    "        'H_frame_diff': H_frame_diff,\n",
    "        'game_id': play_data['game_id'],\n",
    "        'play_id': play_data['play_id'],\n",
    "        'player_ids': play_data['player_ids'],\n",
    "        'star_player_id': play_data['player_ids'][star_idx] if star_idx < len(play_data['player_ids']) else None\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_heliocentricity_for_all(results):\n",
    "    \"\"\"\n",
    "    Compute Heliocentricity for all plays in evaluation results.\n",
    "    \n",
    "    Args:\n",
    "        results: List of result dictionaries from evaluate_model\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with Heliocentricity scores and metadata\n",
    "    \"\"\"\n",
    "    helio_results = []\n",
    "    \n",
    "    for play_data in results:\n",
    "        helio = compute_heliocentricity(play_data)\n",
    "        helio_results.append(helio)\n",
    "    \n",
    "    # Convert to DataFrame for easy analysis\n",
    "    df = pd.DataFrame([{\n",
    "        'game_id': r['game_id'],\n",
    "        'play_id': r['play_id'],\n",
    "        'H_score': r['H_score'],\n",
    "        'star_player_id': r['star_player_id']\n",
    "    } for r in helio_results])\n",
    "    \n",
    "    return df, helio_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2065098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compute Heliocentricity Scores ===\n",
    "\n",
    "# Compute Heliocentricity for all evaluated plays\n",
    "helio_df, helio_results = compute_heliocentricity_for_all(results)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== Heliocentricity Summary ===\")\n",
    "print(helio_df.describe())\n",
    "\n",
    "# Show top 5 plays by Heliocentricity score\n",
    "print(\"\\n=== Top 5 Plays by Heliocentricity ===\")\n",
    "top_plays = helio_df.nlargest(5, 'H_score')\n",
    "print(top_plays)\n",
    "\n",
    "# Example: Access detailed results for a specific play\n",
    "if helio_results:\n",
    "    print(\"\\n=== Sample Detailed Result ===\")\n",
    "    sample = helio_results[0]\n",
    "    print(f\"Game ID: {sample['game_id']}, Play ID: {sample['play_id']}\")\n",
    "    print(f\"Star Player ID: {sample['star_player_id']}\")\n",
    "    print(f\"Heliocentricity Score: {sample['H_score']:.4f}\")\n",
    "    print(f\"Frame-by-frame values shape: {sample['H_frame_diff'].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
