{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2088910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "# Data dimensions from Big Data Bowl (from dataclean.ipynb processing)\n",
    "T_HIST = 25         # Number of historical frames (max in dataset)\n",
    "T_PRED = 25         # Number of frames to predict (max in dataset)\n",
    "N_AGENTS = 9        # Actual number of agents per frame in data\n",
    "D_AGENT = 33        # Agent features: player_height, player_weight, s, a, dir, o, x_rel, y_rel + one-hot encoded position/side/role\n",
    "D_GLOBAL = 18       # Global features: down, yards_to_go + one-hot encoded dropback_type, team_coverage_type\n",
    "\n",
    "# Model architecture hyperparameters\n",
    "D_MODEL = 128       # Transformer Embedding Dimension\n",
    "D_LATENT = 32       # Latent variable Z dimension\n",
    "N_HEADS = 8         # Transformer Heads\n",
    "N_LAYERS = 3        # Transformer Encoder Layers\n",
    "KL_BETA = 0.01      # KL Loss Weight (needs tuning/annealing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "589959a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeliocentricityTransformer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Unpack kwargs for clarity\n",
    "        self.T_HIST, self.T_PRED, self.N_AGENTS = kwargs['T_HIST'], kwargs['T_PRED'], kwargs['N_AGENTS']\n",
    "        self.D_AGENT, self.D_GLOBAL, self.D_MODEL = kwargs['D_AGENT'], kwargs['D_GLOBAL'], kwargs['D_MODEL']\n",
    "        self.D_LATENT, self.N_HEADS, self.N_LAYERS = kwargs['D_LATENT'], kwargs['N_HEADS'], kwargs['N_LAYERS']\n",
    "        self.KL_BETA = kwargs['KL_BETA']\n",
    "        \n",
    "        # --- 1. Initial Embedding Layers ---\n",
    "        self.agent_embed = nn.Linear(self.D_AGENT, self.D_MODEL)\n",
    "        self.global_embed = nn.Linear(self.D_GLOBAL, self.D_MODEL)\n",
    "        \n",
    "        # --- 2. Transformer Encoder (Core STT) ---\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.D_MODEL, \n",
    "            nhead=self.N_HEADS, \n",
    "            dim_feedforward=self.D_MODEL * 4, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=self.N_LAYERS)\n",
    "        \n",
    "        # --- 3. CVAE Heads (Prediction Heads from Context C) ---\n",
    "        # CAVE requires a context vector (C) for prior/recognition networks\n",
    "        \n",
    "        # CVAE: Prior Network (p(z|C)) -> outputs mu_prior, log_var_prior\n",
    "        self.mlp_prior = nn.Sequential(\n",
    "            nn.Linear(self.D_MODEL, self.D_MODEL),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.D_MODEL, 2 * self.D_LATENT)\n",
    "        )\n",
    "\n",
    "        # CVAE: Recognition Network (q(z|C, Y_truth)) -> outputs mu_rec, log_var_rec\n",
    "        # Input is C + flattened Y_truth (context + ground truth trajectory)\n",
    "        self.mlp_recognition = nn.Sequential(\n",
    "            nn.Linear(self.D_MODEL + self.T_PRED * self.N_AGENTS * 2, self.D_MODEL),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.D_MODEL, 2 * self.D_LATENT)\n",
    "        )\n",
    "\n",
    "        # --- 4. Decoder Head (Trajectory Generator) ---\n",
    "        # Input is C + Z. Output is the flattened trajectory (x, y coordinates)\n",
    "        self.mlp_decoder = nn.Sequential(\n",
    "            nn.Linear(self.D_MODEL + self.D_LATENT, self.D_MODEL * 2),\n",
    "            nn.ReLU(),\n",
    "            # Output shape: (Batch, T_PRED * N_AGENTS * 2)\n",
    "            nn.Linear(self.D_MODEL * 2, self.T_PRED * self.N_AGENTS * 2)\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        # Sampling Z = mu + sigma * epsilon\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, X_hist_agents, X_global, Y_truth=None):\n",
    "        B = X_hist_agents.size(0)\n",
    "        \n",
    "        # 1. Agent Embedding (Per-Frame)\n",
    "        # (B, T_hist, N_agents, D_agent) -> (B, T_hist, N_agents, D_MODEL)\n",
    "        agent_emb = self.agent_embed(X_hist_agents)\n",
    "        \n",
    "        # 2. Global CLS Token Embedding\n",
    "        # (B, D_global) -> (B, D_MODEL)\n",
    "        global_emb = self.global_embed(X_global)\n",
    "        # Expand for T_hist: (B, 1, 1, D_MODEL). Expand(T_hist) not needed as we use flatten below\n",
    "        \n",
    "        # 3. Prepare Sequence for Transformer\n",
    "        \n",
    "        # Create CLS Token for each time step in the historical sequence\n",
    "        # Shape: (B, T_hist, 1, D_MODEL)\n",
    "        cls_tokens = global_emb.unsqueeze(1).unsqueeze(1).expand(-1, self.T_HIST, -1, -1)\n",
    "        \n",
    "        # Concatenate CLS token to the front of each frame's set of agents\n",
    "        # Shape: (B, T_hist, N_agents + 1, D_MODEL)\n",
    "        input_sequence = torch.cat([cls_tokens, agent_emb], dim=2)\n",
    "        \n",
    "        # Flatten time and agent dimensions for Transformer input\n",
    "        # Shape: (B, T_hist * (N_agents + 1), D_MODEL)\n",
    "        flat_input = input_sequence.view(B, -1, self.D_MODEL)\n",
    "        \n",
    "        # Add Positional/Temporal Encoding here (Omitted)\n",
    "        \n",
    "        # 4. Transformer Encoding\n",
    "        # Encoded_Output: (B, T_hist * (N_agents + 1), D_MODEL)\n",
    "        encoded_output = self.transformer_encoder(flat_input)\n",
    "        \n",
    "        # 5. Extract Context Vector C from the first CLS token\n",
    "        # The first token is CLS at t=0. C should capture the full context.\n",
    "        # Context C: (B, D_MODEL)\n",
    "        C = encoded_output[:, 0, :]\n",
    "        \n",
    "        # --- CVAE Latent Space ---\n",
    "        # Prior Network: p(z|C)\n",
    "        mu_prior, log_var_prior = self.mlp_prior(C).chunk(2, dim=-1)\n",
    "\n",
    "        # Recognition Network: q(z|C, Y_truth) is only used during training\n",
    "        if Y_truth is not None:\n",
    "            # Flatten Y_truth: (B, T_pred * N_agents * 2)\n",
    "            Y_flat = Y_truth.view(B, -1)\n",
    "            rec_input = torch.cat([C, Y_flat], dim=-1)\n",
    "            mu_rec, log_var_rec = self.mlp_recognition(rec_input).chunk(2, dim=-1)\n",
    "            Z = self.reparameterize(mu_rec, log_var_rec)\n",
    "        else:\n",
    "            # Inference: Sample Z from the Prior distribution p(z|C)\n",
    "            # This is key for generating diverse, expected trajectories (E)\n",
    "            Z = self.reparameterize(mu_prior, log_var_prior)\n",
    "            mu_rec, log_var_rec = mu_prior, log_var_prior # Use prior stats for loss calc placeholder\n",
    "\n",
    "        # --- Decoder ---\n",
    "        # Input: [C, Z]\n",
    "        decoder_input = torch.cat([C, Z], dim=-1)\n",
    "        \n",
    "        # Output: (B, T_pred * N_agents * 2)\n",
    "        Y_pred_flat = self.mlp_decoder(decoder_input)\n",
    "        \n",
    "        # Reshape to (B, T_pred, N_agents, 2)\n",
    "        Y_pred = Y_pred_flat.view(B, self.T_PRED, self.N_AGENTS, 2)\n",
    "        \n",
    "        return Y_pred, mu_rec, log_var_rec, mu_prior, log_var_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7b44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(Y_pred, Y_truth, mu_rec, log_var_rec, mu_prior, log_var_prior, KL_BETA):\n",
    "    # 1. Reconstruction Loss (L_recon): RMSE on the predicted x, y coordinates\n",
    "    # We use MSE here for simplicity in PyTorch, but RMSE is the metric.\n",
    "    L_recon = F.mse_loss(Y_pred, Y_truth, reduction='sum') / Y_pred.size(0) # Mean over batch\n",
    "\n",
    "    # 2. KL Divergence Loss (L_KL): KL(q(z|C, Y) || p(z|C))\n",
    "    # Closed-form KL for Gaussian: 0.5 * sum(1 + log(sigma_prior^2) - log(sigma_rec^2) - (mu_rec - mu_prior)^2 / sigma_prior^2 - exp(log(sigma_rec^2)) / sigma_prior^2)\n",
    "    # Using torch.exp(log_var) = sigma^2\n",
    "    kl_loss = 0.5 * torch.sum(\n",
    "        log_var_prior - log_var_rec - 1 \n",
    "        + (torch.exp(log_var_rec) + (mu_rec - mu_prior).pow(2)) / torch.exp(log_var_prior)\n",
    "    ) / Y_pred.size(0)\n",
    "\n",
    "    # Total Loss (Weighted sum)\n",
    "    total_loss = L_recon + KL_BETA * kl_loss\n",
    "    return total_loss, L_recon.item(), kl_loss.item()\n",
    "\n",
    "# --- Heliocentricity Inference Function (E Generator) ---\n",
    "@torch.no_grad()\n",
    "def generate_expected_trajectories(model, X_hist_agents, X_global, K=10):\n",
    "    \"\"\"\n",
    "    Generates K diverse, plausible trajectories for the defense (E) \n",
    "    by sampling the latent space Z from the prior distribution.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    B = X_hist_agents.size(0)\n",
    "    \n",
    "    # Repeat inputs K times to batch the K samples\n",
    "    X_hist_agents_K = X_hist_agents.repeat_interleave(K, dim=0)\n",
    "    X_global_K = X_global.repeat_interleave(K, dim=0)\n",
    "\n",
    "    # Since Y_truth=None, Z is sampled from the prior p(z|C)\n",
    "    Y_pred_K, _, _, _, _ = model(X_hist_agents_K, X_global_K, Y_truth=None)\n",
    "    \n",
    "    # Reshape: (B * K, T_pred, N_agents, 2) -> (B, K, T_pred, N_agents, 2)\n",
    "    return Y_pred_K.view(B, K, model.T_PRED, model.N_AGENTS, 2)\n",
    "\n",
    "# Note: The final step of calculating Heliocentricity (H) based on \n",
    "# min separation distance (A vs E) is a NumPy/Pandas operation after this PyTorch step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7d27a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataset/processed/processed_data.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/cfchh_0s3zv0_x826rm19h1r0000gn/T/ipykernel_4704/3548729986.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load(data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14108 plays\n",
      "Global context shape: torch.Size([14108, 18])\n",
      "Created DataLoader with 14108 samples, batch size 64\n",
      "Max hist length: 25, Max pred length: 25, Max agents: 9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Setup: Instantiate Model and Optimizer ---\n",
    "\n",
    "# Define a dictionary for easy configuration\n",
    "model_config = {\n",
    "    'T_HIST': 25, 'T_PRED': 25, 'N_AGENTS': 9, 'D_AGENT': 33, \n",
    "    'D_GLOBAL': 18, 'D_MODEL': 128, 'D_LATENT': 32, 'N_HEADS': 8, \n",
    "    'N_LAYERS': 3, 'KL_BETA': 0.01 \n",
    "}\n",
    "\n",
    "# Instantiate the model and move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HeliocentricityTransformer(**model_config).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# --- 2. Load Big Data Bowl Data from Disk ---\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Load processed data\n",
    "data_path = Path('dataset/processed/processed_data.pt')\n",
    "print(f\"Loading data from {data_path}...\")\n",
    "loaded_data = torch.load(data_path)\n",
    "\n",
    "# Extract data\n",
    "historical_agent_features = loaded_data['historical_agent_features']\n",
    "ground_truth_trajectories = loaded_data['ground_truth_trajectories']\n",
    "global_context_features = loaded_data['global_context_features']\n",
    "\n",
    "print(f\"Loaded {len(historical_agent_features)} plays\")\n",
    "print(f\"Global context shape: {global_context_features.shape}\")\n",
    "\n",
    "# Custom Dataset with Padding (both time and agent dimensions)\n",
    "class FootballDataset(Dataset):\n",
    "    def __init__(self, hist_features, gt_trajectories, global_features, max_hist_len=None, max_pred_len=None, max_n_agents=None):\n",
    "        self.hist_features = hist_features\n",
    "        self.gt_trajectories = gt_trajectories\n",
    "        self.global_features = global_features\n",
    "        \n",
    "        # Determine max lengths if not provided\n",
    "        self.max_hist_len = max_hist_len or max(x.shape[0] for x in hist_features)\n",
    "        self.max_pred_len = max_pred_len or max(y.shape[0] for y in gt_trajectories)\n",
    "        self.max_n_agents = max_n_agents or max(x.shape[1] for x in hist_features)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hist_features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        hist = self.hist_features[idx]  # (T_hist_actual, N_agents_actual, D_agent)\n",
    "        gt = self.gt_trajectories[idx]  # (T_pred_actual, N_agents_actual, 2)\n",
    "        global_feat = self.global_features[idx]  # (D_global,)\n",
    "        \n",
    "        # Get actual lengths\n",
    "        hist_len = hist.shape[0]\n",
    "        pred_len = gt.shape[0]\n",
    "        n_agents = hist.shape[1]\n",
    "        \n",
    "        # Pad historical features to max_hist_len and max_n_agents\n",
    "        # First pad time dimension\n",
    "        if hist_len < self.max_hist_len:\n",
    "            pad_hist_time = torch.zeros(self.max_hist_len - hist_len, hist.shape[1], hist.shape[2], dtype=hist.dtype)\n",
    "            hist = torch.cat([hist, pad_hist_time], dim=0)\n",
    "        else:\n",
    "            hist = hist[:self.max_hist_len]\n",
    "            hist_len = self.max_hist_len\n",
    "        \n",
    "        # Then pad agent dimension\n",
    "        if n_agents < self.max_n_agents:\n",
    "            pad_hist_agents = torch.zeros(hist.shape[0], self.max_n_agents - n_agents, hist.shape[2], dtype=hist.dtype)\n",
    "            hist_padded = torch.cat([hist, pad_hist_agents], dim=1)\n",
    "        else:\n",
    "            hist_padded = hist[:, :self.max_n_agents, :]\n",
    "            n_agents = self.max_n_agents\n",
    "        \n",
    "        # Pad ground truth to max_pred_len and max_n_agents\n",
    "        # First pad time dimension\n",
    "        if pred_len < self.max_pred_len:\n",
    "            pad_gt_time = torch.zeros(self.max_pred_len - pred_len, gt.shape[1], 2, dtype=gt.dtype)\n",
    "            gt = torch.cat([gt, pad_gt_time], dim=0)\n",
    "        else:\n",
    "            gt = gt[:self.max_pred_len]\n",
    "            pred_len = self.max_pred_len\n",
    "        \n",
    "        # Then pad agent dimension\n",
    "        if gt.shape[1] < self.max_n_agents:\n",
    "            pad_gt_agents = torch.zeros(gt.shape[0], self.max_n_agents - gt.shape[1], 2, dtype=gt.dtype)\n",
    "            gt_padded = torch.cat([gt, pad_gt_agents], dim=1)\n",
    "        else:\n",
    "            gt_padded = gt[:, :self.max_n_agents, :]\n",
    "        \n",
    "        return hist_padded, global_feat, gt_padded, hist_len, pred_len\n",
    "\n",
    "# Create dataset with padding\n",
    "# Use model config values as max lengths\n",
    "dataset = FootballDataset(\n",
    "    historical_agent_features, \n",
    "    ground_truth_trajectories, \n",
    "    global_context_features,\n",
    "    max_hist_len=model_config['T_HIST'],\n",
    "    max_pred_len=model_config['T_PRED'],\n",
    "    max_n_agents=model_config['N_AGENTS']\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"Created DataLoader with {len(dataset)} samples, batch size {BATCH_SIZE}\")\n",
    "print(f\"Max hist length: {dataset.max_hist_len}, Max pred length: {dataset.max_pred_len}, Max agents: {dataset.max_n_agents}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37835750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cpu...\n",
      "  Batch 100/221 | Total Loss: 1203.1502 | Recon: 1200.9879 | KL: 216.2308\n",
      "  Batch 100/221 | Total Loss: 1203.1502 | Recon: 1200.9879 | KL: 216.2308\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m L_recon \u001b[38;5;241m+\u001b[39m model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKL_BETA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m kl_loss\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 4. Backward Pass and Optimization\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Optional: Gradient clipping to stabilize Transformer training\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0) \u001b[39;00m\n\u001b[1;32m     59\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- 3. The Training Loop with Masking ---\n",
    "\n",
    "def create_mask(lengths, max_len, device):\n",
    "    \"\"\"Create attention mask: True for valid positions, False for padding\"\"\"\n",
    "    batch_size = len(lengths)\n",
    "    mask = torch.arange(max_len, device=device).expand(batch_size, max_len) < lengths.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "def train_model(model, train_loader, optimizer, model_config, device, num_epochs=20):\n",
    "    \"\"\"\n",
    "    Train the Heliocentricity Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        model: The HeliocentricityTransformer model\n",
    "        train_loader: DataLoader for training data\n",
    "        optimizer: Optimizer for training\n",
    "        model_config: Dictionary with model configuration\n",
    "        device: Device to train on (cuda/cpu)\n",
    "        num_epochs: Number of epochs to train\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with training history\n",
    "    \"\"\"\n",
    "    print(f\"Starting training on {device}...\")\n",
    "    \n",
    "    history = {\n",
    "        'total_loss': [],\n",
    "        'recon_loss': [],\n",
    "        'kl_loss': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_kl_loss = 0\n",
    "        \n",
    "        for batch_idx, (X_agents, X_global, Y_truth, hist_lens, pred_lens) in enumerate(train_loader):\n",
    "            \n",
    "            # Move to device\n",
    "            X_agents = X_agents.to(device)\n",
    "            X_global = X_global.to(device)\n",
    "            Y_truth = Y_truth.to(device)\n",
    "            hist_lens = hist_lens.to(device)\n",
    "            pred_lens = pred_lens.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 1. Forward Pass\n",
    "            # The forward pass uses the recognition network q(z|C, Y_truth) since Y_truth is provided.\n",
    "            Y_pred, mu_rec, log_var_rec, mu_prior, log_var_prior = model(X_agents, X_global, Y_truth=Y_truth)\n",
    "            \n",
    "            # 2. Create mask for ground truth prediction loss\n",
    "            # Only compute loss on valid (non-padded) timesteps\n",
    "            pred_mask = create_mask(pred_lens, model_config['T_PRED'], device)\n",
    "            # Expand mask to match Y_pred shape: (B, T_pred, N_agents, 2)\n",
    "            pred_mask_expanded = pred_mask.unsqueeze(-1).unsqueeze(-1).expand_as(Y_pred)\n",
    "            \n",
    "            # Apply mask to predictions and ground truth\n",
    "            Y_pred_masked = Y_pred * pred_mask_expanded\n",
    "            Y_truth_masked = Y_truth * pred_mask_expanded\n",
    "            \n",
    "            # 3. Compute VAE Loss with masked outputs\n",
    "            # Reconstruction loss only on valid timesteps\n",
    "            L_recon = F.mse_loss(Y_pred_masked, Y_truth_masked, reduction='sum') / pred_lens.sum()\n",
    "            \n",
    "            # KL loss (not masked, as it's based on latent distribution)\n",
    "            kl_loss = 0.5 * torch.sum(\n",
    "                log_var_prior - log_var_rec - 1 \n",
    "                + (torch.exp(log_var_rec) + (mu_rec - mu_prior).pow(2)) / torch.exp(log_var_prior)\n",
    "            ) / X_agents.size(0)\n",
    "            \n",
    "            loss = L_recon + model_config['KL_BETA'] * kl_loss\n",
    "            \n",
    "            # 4. Backward Pass and Optimization\n",
    "            loss.backward()\n",
    "            # Optional: Gradient clipping to stabilize Transformer training\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0) \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += L_recon.item()\n",
    "            total_kl_loss += kl_loss.item()\n",
    "            \n",
    "            # Print update every 100 batches\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"  Batch {batch_idx+1}/{len(train_loader)} | Total Loss: {total_loss / (batch_idx+1):.4f} | Recon: {total_recon_loss / (batch_idx+1):.4f} | KL: {total_kl_loss / (batch_idx+1):.4f}\")\n",
    "    \n",
    "        # --- End of Epoch ---\n",
    "        avg_epoch_loss = total_loss / len(train_loader)\n",
    "        avg_recon = total_recon_loss / len(train_loader)\n",
    "        avg_kl = total_kl_loss / len(train_loader)\n",
    "        \n",
    "        history['total_loss'].append(avg_epoch_loss)\n",
    "        history['recon_loss'].append(avg_recon)\n",
    "        history['kl_loss'].append(avg_kl)\n",
    "        \n",
    "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} Complete ---\")\n",
    "        print(f\"Average Total Loss: {avg_epoch_loss:.4f} | Recon: {avg_recon:.4f} | KL: {avg_kl:.4f}\")\n",
    "        \n",
    "        # Optional: Implement a validation loop here and save the best model weights\n",
    "        # torch.save(model.state_dict(), f\"best_heliocentricity_model.pt\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Run training\n",
    "# training_history = train_model(model, train_loader, optimizer, model_config, device, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cfcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the saved model weights\n",
    "# model.load_state_dict(torch.load(\"best_heliocentricity_model.pt\"))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_rmse = []\n",
    "    total_recon_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    \n",
    "    # Store data for final Heliocentricity calculation outside the loop\n",
    "    results_for_H_calc = [] \n",
    "\n",
    "    for X_agents, X_global, Y_truth in data_loader:\n",
    "        \n",
    "        # Move data to device\n",
    "        X_agents, X_global, Y_truth = X_agents.to(device), X_global.to(device), Y_truth.to(device)\n",
    "\n",
    "        # 1. Deterministic Prediction (for Reconstruction Loss)\n",
    "        # Uses the recognition network q(z|C, Y_truth) which yields the best reconstruction\n",
    "        Y_pred, mu_rec, log_var_rec, mu_prior, log_var_prior = model(X_agents, X_global, Y_truth=Y_truth)\n",
    "        \n",
    "        # Calculate Loss components\n",
    "        loss, L_recon, L_KL = vae_loss(\n",
    "            Y_pred, Y_truth, \n",
    "            mu_rec, log_var_rec, mu_prior, log_var_prior, \n",
    "            model.KL_BETA\n",
    "        )\n",
    "        total_recon_loss += L_recon\n",
    "        total_kl_loss += L_KL\n",
    "\n",
    "        # 2. Calculate Root Mean Squared Error (RMSE) on the deterministic prediction\n",
    "        # Detach and convert to numpy for standard metric calculation\n",
    "        Y_pred_np = Y_pred.cpu().numpy()\n",
    "        Y_truth_np = Y_truth.cpu().numpy()\n",
    "        \n",
    "        # Calculate RMSE for each sample and average (Flattening all T_pred * N_agents * 2 dimensions)\n",
    "        sample_rmse = np.sqrt(mean_squared_error(Y_truth_np.reshape(-1, 1), Y_pred_np.reshape(-1, 1)))\n",
    "        total_rmse.append(sample_rmse)\n",
    "\n",
    "        # 3. Generate K Stochastic Predictions for Heliocentricity (E)\n",
    "        # This uses the prior network p(z|C) for diverse sampling\n",
    "        K = 10 # Number of samples per play\n",
    "        Y_pred_K = generate_expected_trajectories(model, X_agents, X_global, K=K).cpu().numpy()\n",
    "        \n",
    "        # Store results (You would need to include the actual Star Receiver ID/Index here)\n",
    "        for i in range(Y_truth_np.shape[0]):\n",
    "            results_for_H_calc.append({\n",
    "                'Y_truth': Y_truth_np[i],\n",
    "                'Y_pred_K': Y_pred_K[i],\n",
    "                # Assume you have a way to link back to the play ID and the Star Receiver Index\n",
    "                'star_idx': 4 # Pseudo-Index for the star receiver\n",
    "            })\n",
    "\n",
    "    avg_rmse = np.mean(total_rmse)\n",
    "    avg_recon = total_recon_loss / len(data_loader)\n",
    "    avg_kl = total_kl_loss / len(data_loader)\n",
    "    \n",
    "    print(f\"\\n--- Validation Results ---\")\n",
    "    print(f\"Avg Trajectory RMSE: {avg_rmse:.4f} meters\")\n",
    "    print(f\"Avg Reconstruction Loss: {avg_recon:.4f}\")\n",
    "    print(f\"Avg KL Divergence: {avg_kl:.4f}\")\n",
    "    \n",
    "    return results_for_H_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_separation_distance(receiver_coords, defense_coords):\n",
    "    # receiver_coords: (T_pred, 2)\n",
    "    # defense_coords: (T_pred, N_defenders, 2)\n",
    "    \n",
    "    # Calculate distance from receiver to every defender at every frame\n",
    "    # (T_pred, N_defenders)\n",
    "    dist_to_defenders = np.linalg.norm(\n",
    "        receiver_coords[:, np.newaxis, :] - defense_coords, axis=2\n",
    "    )\n",
    "    \n",
    "    # Find the minimum separation at each frame (T_pred,)\n",
    "    min_dist = np.min(dist_to_defenders, axis=1)\n",
    "    return min_dist # Actual Attention (A) or Expected Coverage (E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heliocentricity(play_data):\n",
    "    # Data is extracted from the evaluation loop's results_for_H_calc\n",
    "    Y_truth = play_data['Y_truth']       # (T_pred, N_agents, 2)\n",
    "    Y_pred_K = play_data['Y_pred_K']     # (K, T_pred, N_agents, 2)\n",
    "    star_idx = play_data['star_idx']     # Index of the star receiver\n",
    "    \n",
    "    # --- 1. Identify Offensive/Defensive Players ---\n",
    "    # Assuming player 0-10 are Offense, 11-21 are Defense (Adjust based on BDB index)\n",
    "    def_indices = np.arange(11, 22) \n",
    "    \n",
    "    # --- 2. Calculate Actual Attention (A) ---\n",
    "    actual_R_coords = Y_truth[:, star_idx, :]\n",
    "    actual_D_coords = Y_truth[:, def_indices, :]\n",
    "    A = min_separation_distance(actual_R_coords, actual_D_coords) # (T_pred,)\n",
    "    \n",
    "    # --- 3. Calculate Expected Coverage (E) ---\n",
    "    E_K = []\n",
    "    for k in range(Y_pred_K.shape[0]):\n",
    "        # The star receiver's true position is used, but compared to predicted defense\n",
    "        predicted_D_coords = Y_pred_K[k, :, def_indices, :] \n",
    "        \n",
    "        # E_k is the min separation based on the k-th predicted defensive trajectory\n",
    "        E_k = min_separation_distance(actual_R_coords, predicted_D_coords)\n",
    "        E_K.append(E_k)\n",
    "        \n",
    "    # E_mean: The average expected minimum separation across all K samples (T_pred,)\n",
    "    E_mean = np.mean(np.stack(E_K, axis=0), axis=0) \n",
    "    \n",
    "    # --- 4. Calculate Heliocentricity (H) ---\n",
    "    # H = (E - A) averaged over the prediction window (T_pred)\n",
    "    H_frame_diff = E_mean - A\n",
    "    H_score = np.mean(H_frame_diff)\n",
    "    \n",
    "    return H_score, H_frame_diff # Return both the scalar and the time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking Data Dimensions ===\n",
      "Sample historical features shape: torch.Size([25, 9, 33])\n",
      "  Expected: (T_hist, N_agents, D_agent)\n",
      "  Model expects: (25, 9, 33)\n",
      "\n",
      "Sample ground truth shape: torch.Size([25, 9, 2])\n",
      "  Expected: (T_pred, N_agents, 2)\n",
      "  Model expects: (25, 9, 2)\n",
      "\n",
      "Sample global features shape: torch.Size([18])\n",
      "  Expected: (D_global,)\n",
      "  Model expects: (18,)\n",
      "\n",
      "=== Actual Data Statistics ===\n",
      "Number of agents in data: 9\n",
      "Agent feature dimension: 33\n",
      "Global feature dimension: 18\n",
      "\n",
      "=== Testing DataLoader ===\n",
      "Error getting batch: stack expects each tensor to be equal size, but got [25, 10, 33] at entry 0 and [25, 13, 33] at entry 1\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check actual data dimensions and first batch\n",
    "print(\"=== Checking Data Dimensions ===\")\n",
    "sample_hist = historical_agent_features[0]\n",
    "sample_gt = ground_truth_trajectories[0]\n",
    "sample_global = global_context_features[0]\n",
    "\n",
    "print(f\"Sample historical features shape: {sample_hist.shape}\")\n",
    "print(f\"  Expected: (T_hist, N_agents, D_agent)\")\n",
    "print(f\"  Model expects: ({model_config['T_HIST']}, {model_config['N_AGENTS']}, {model_config['D_AGENT']})\")\n",
    "\n",
    "print(f\"\\nSample ground truth shape: {sample_gt.shape}\")\n",
    "print(f\"  Expected: (T_pred, N_agents, 2)\")\n",
    "print(f\"  Model expects: ({model_config['T_PRED']}, {model_config['N_AGENTS']}, 2)\")\n",
    "\n",
    "print(f\"\\nSample global features shape: {sample_global.shape}\")\n",
    "print(f\"  Expected: (D_global,)\")\n",
    "print(f\"  Model expects: ({model_config['D_GLOBAL']},)\")\n",
    "\n",
    "# Check what dimensions we actually have in the data\n",
    "print(\"\\n=== Actual Data Statistics ===\")\n",
    "print(f\"Number of agents in data: {sample_hist.shape[1] if len(sample_hist.shape) > 1 else 'N/A'}\")\n",
    "print(f\"Agent feature dimension: {sample_hist.shape[2] if len(sample_hist.shape) > 2 else 'N/A'}\")\n",
    "print(f\"Global feature dimension: {sample_global.shape[0] if len(sample_global.shape) > 0 else 'N/A'}\")\n",
    "\n",
    "# Test getting a batch from the dataloader\n",
    "print(\"\\n=== Testing DataLoader ===\")\n",
    "try:\n",
    "    batch = next(iter(train_loader))\n",
    "    X_agents_batch, X_global_batch, Y_truth_batch, hist_lens_batch, pred_lens_batch = batch\n",
    "    print(f\"Batch X_agents shape: {X_agents_batch.shape}\")\n",
    "    print(f\"Batch X_global shape: {X_global_batch.shape}\")\n",
    "    print(f\"Batch Y_truth shape: {Y_truth_batch.shape}\")\n",
    "    print(f\"Batch hist_lens: {hist_lens_batch[:5]}\")\n",
    "    print(f\"Batch pred_lens: {pred_lens_batch[:5]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting batch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120d2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking for variable agent counts ===\n",
      "Play 0: hist shape torch.Size([25, 9, 33]), gt shape torch.Size([25, 9, 2])\n",
      "Play 1: hist shape torch.Size([31, 13, 33]), gt shape torch.Size([31, 13, 2])\n",
      "Play 2: hist shape torch.Size([16, 13, 33]), gt shape torch.Size([16, 13, 2])\n",
      "Play 3: hist shape torch.Size([50, 11, 33]), gt shape torch.Size([50, 11, 2])\n",
      "Play 4: hist shape torch.Size([19, 11, 33]), gt shape torch.Size([19, 11, 2])\n",
      "Play 5: hist shape torch.Size([22, 13, 33]), gt shape torch.Size([22, 13, 2])\n",
      "Play 6: hist shape torch.Size([19, 13, 33]), gt shape torch.Size([19, 13, 2])\n",
      "Play 7: hist shape torch.Size([28, 13, 33]), gt shape torch.Size([28, 13, 2])\n",
      "Play 8: hist shape torch.Size([23, 13, 33]), gt shape torch.Size([23, 13, 2])\n",
      "Play 9: hist shape torch.Size([30, 12, 33]), gt shape torch.Size([30, 12, 2])\n"
     ]
    }
   ],
   "source": [
    "# Check for variable number of agents per frame\n",
    "print(\"=== Checking for variable agent counts ===\")\n",
    "for i in range(min(10, len(historical_agent_features))):\n",
    "    hist = historical_agent_features[i]\n",
    "    gt = ground_truth_trajectories[i]\n",
    "    print(f\"Play {i}: hist shape {hist.shape}, gt shape {gt.shape}\")\n",
    "    \n",
    "    # Check if N_agents is consistent across all frames in this play\n",
    "    if len(hist.shape) >= 3:\n",
    "        for t in range(hist.shape[0]):\n",
    "            if t > 0 and hist.shape[1] != historical_agent_features[i][0].shape[0]:\n",
    "                print(f\"  WARNING: Frame {t} has different number of agents!\")\n",
    "                \n",
    "# The problem is likely that different PLAYS have different numbers of agents\n",
    "# We need to pad the agent dimension too, not just the time dimension"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
