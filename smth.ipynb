{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION (MAP YOUR COLUMNS HERE)\n",
    "# ==========================================\n",
    "FEATURE_CONFIG = {\n",
    "    # Continuous features to normalize and input\n",
    "    'continuous_cols': ['x', 'y', 's', 'dir', 'o'], \n",
    "    \n",
    "    # Categorical/Static features\n",
    "    'role_col': 'role_label',       # e.g., 0=CB, 1=LB, 2=S...\n",
    "    'coverage_col': 'coverage_type', # e.g., 0=Man, 1=Zone...\n",
    "    \n",
    "    # Dimensions\n",
    "    'num_agents': 22,      # 11 Offense + 11 Defense (or 23 with ball)\n",
    "    'num_roles': 10,       # Max number of unique position roles\n",
    "    'num_coverages': 5,    # Max number of coverage types\n",
    "    'input_dim': 5,        # Length of 'continuous_cols'\n",
    "    'hidden_dim': 256,\n",
    "    'latent_dim': 32,\n",
    "    'nhead': 4,\n",
    "    'num_layers': 4\n",
    "}\n",
    "\n",
    "class DefensiveGhostModel(pl.LightningModule):\n",
    "    def __init__(self, cfg=FEATURE_CONFIG):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # A. Embeddings (Feature Extraction)\n",
    "        # -------------------------------------------------------\n",
    "        # Projects continuous features (x, y, s...) to hidden_dim\n",
    "        self.feature_embedding = nn.Linear(cfg['input_dim'], cfg['hidden_dim'])\n",
    "        \n",
    "        # Learnable embeddings for discrete inputs\n",
    "        self.role_embedding = nn.Embedding(cfg['num_roles'], cfg['hidden_dim'])\n",
    "        self.coverage_embedding = nn.Embedding(cfg['num_coverages'], cfg['hidden_dim'])\n",
    "        \n",
    "        # Positional Encoding (Temporal)\n",
    "        self.pos_encoder = PositionalEncoding(cfg['hidden_dim'])\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # B. The Encoders (Transformer)\n",
    "        # -------------------------------------------------------\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=cfg['hidden_dim'], \n",
    "            nhead=cfg['nhead'], \n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        \n",
    "        # 1. Past Encoder: Encodes history + context (coverage)\n",
    "        self.past_encoder = nn.TransformerEncoder(encoder_layer, num_layers=cfg['num_layers'])\n",
    "        \n",
    "        # 2. Future Encoder (Training only): Encodes the target future to learn Z\n",
    "        self.future_encoder = nn.TransformerEncoder(encoder_layer, num_layers=cfg['num_layers'] // 2)\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # C. The Latent Space (CVAE)\n",
    "        # -------------------------------------------------------\n",
    "        # Maps \"Future Info\" -> Mean (mu) and Log-Variance (logvar)\n",
    "        self.z_mean = nn.Linear(cfg['hidden_dim'], cfg['latent_dim'])\n",
    "        self.z_logvar = nn.Linear(cfg['hidden_dim'], cfg['latent_dim'])\n",
    "        \n",
    "        # Projects Z back to hidden dimension to merge with Past\n",
    "        self.z_projection = nn.Linear(cfg['latent_dim'], cfg['hidden_dim'])\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # D. The Decoder (Trajectory Generator)\n",
    "        # -------------------------------------------------------\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=cfg['hidden_dim'], \n",
    "            nhead=cfg['nhead'], \n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.trajectory_decoder = nn.TransformerDecoder(decoder_layer, num_layers=cfg['num_layers'])\n",
    "\n",
    "        # Output Head: Predicts (x, y) coordinates (or velocity)\n",
    "        self.output_head = nn.Linear(cfg['hidden_dim'], 2) \n",
    "\n",
    "    def embed_agents(self, x, roles):\n",
    "        \"\"\"Helper to combine continuous features + role embeddings\"\"\"\n",
    "        # x shape: (Batch, Time, Agents, Features)\n",
    "        B, T, A, F_dim = x.shape\n",
    "        \n",
    "        # Flatten Batch/Time for Linear Layer\n",
    "        emb = self.feature_embedding(x) # (B, T, A, H)\n",
    "        \n",
    "        # Add Role Embeddings (broadcast across time)\n",
    "        # roles shape: (Batch, Agents) -> (Batch, 1, Agents, H)\n",
    "        role_emb = self.role_embedding(roles).unsqueeze(1)\n",
    "        \n",
    "        return emb + role_emb\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass mainly used for INFERENCE.\n",
    "        Returns predicted trajectory.\n",
    "        \"\"\"\n",
    "        history = batch['history']      # (B, T_obs, A, F)\n",
    "        roles = batch['roles']          # (B, A)\n",
    "        coverage = batch['coverage']    # (B,)\n",
    "        \n",
    "        # 1. Encode History\n",
    "        B, T_obs, A, _ = history.shape\n",
    "        \n",
    "        # Flatten Agents into the Batch dimension or treat as super-sequence\n",
    "        # For simplicity: We pool agents to create a single \"Play State\" per timestep\n",
    "        # (A more advanced version would keep agents separate and use masked attention)\n",
    "        hist_emb = self.embed_agents(history, roles) # (B, T, A, H)\n",
    "        hist_emb = hist_emb.mean(dim=2) # Mean pool over agents -> (B, T, H)\n",
    "        \n",
    "        # Add Coverage Context\n",
    "        cov_emb = self.coverage_embedding(coverage).unsqueeze(1) # (B, 1, H)\n",
    "        hist_emb = hist_emb + cov_emb # Broadcasting addition\n",
    "        \n",
    "        hist_emb = self.pos_encoder(hist_emb)\n",
    "        memory = self.past_encoder(hist_emb)\n",
    "        \n",
    "        # 2. Sample Latent Z (From Prior N(0,1) because we are inferring)\n",
    "        z = torch.randn(B, 1, self.cfg['latent_dim'], device=self.device)\n",
    "        z_proj = self.z_projection(z) # (B, 1, H)\n",
    "        \n",
    "        # 3. Decode Future (Autoregressive loop is usually done here)\n",
    "        # For this example, we generate 'pred_len' steps at once using the memory\n",
    "        tgt_query = z_proj.repeat(1, 50, 1) # Predict 50 frames, repeating Z as query\n",
    "        tgt_query = self.pos_encoder(tgt_query)\n",
    "        \n",
    "        output = self.trajectory_decoder(tgt=tgt_query, memory=memory)\n",
    "        predictions = self.output_head(output) # (B, 50, 2) -> (dx, dy)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        CVAE Training Logic\n",
    "        \"\"\"\n",
    "        history = batch['history']   # Past (t=0 to 10)\n",
    "        future = batch['future']     # Target (t=11 to 60)\n",
    "        roles = batch['roles']\n",
    "        coverage = batch['coverage']\n",
    "        \n",
    "        # --- A. ENCODE PAST ---\n",
    "        hist_emb = self.embed_agents(history, roles).mean(dim=2) # (B, T_past, H)\n",
    "        cov_emb = self.coverage_embedding(coverage).unsqueeze(1)\n",
    "        hist_emb = self.pos_encoder(hist_emb + cov_emb)\n",
    "        memory = self.past_encoder(hist_emb)\n",
    "        \n",
    "        # --- B. ENCODE FUTURE (To learn Z) ---\n",
    "        fut_emb = self.embed_agents(future, roles).mean(dim=2)\n",
    "        fut_emb = self.pos_encoder(fut_emb)\n",
    "        # We take the final hidden state of the future as the \"summary\"\n",
    "        future_summary = self.future_encoder(fut_emb)[:, -1, :] \n",
    "        \n",
    "        # --- C. LATENT SPACE ---\n",
    "        mu = self.z_mean(future_summary)\n",
    "        logvar = self.z_logvar(future_summary)\n",
    "        \n",
    "        # Reparameterization Trick: z = mu + std * eps\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        \n",
    "        # --- D. DECODE ---\n",
    "        # Project Z to be the \"seed\" for the decoder\n",
    "        z_proj = self.z_projection(z).unsqueeze(1) # (B, 1, H)\n",
    "        \n",
    "        # The decoder query needs to be the length of the future\n",
    "        # We combine Z with the future embeddings (Teacher Forcing: feed correct inputs)\n",
    "        # In practice, we usually add Z to the target embeddings\n",
    "        tgt_emb = self.pos_encoder(fut_emb) + z_proj \n",
    "        \n",
    "        # Causal Mask (prevent seeing future positions during decoding)\n",
    "        T_fut = future.shape[1]\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(T_fut).to(self.device)\n",
    "        \n",
    "        pred_output = self.trajectory_decoder(tgt=tgt_emb, memory=memory, tgt_mask=tgt_mask)\n",
    "        pred_coords = self.output_head(pred_output) # Predicted (dx, dy)\n",
    "        \n",
    "        # --- E. LOSS CALCULATION ---\n",
    "        target_coords = future[:, :, :, :2].mean(dim=2) # Taking mean agent movement for simplicity in this snippet\n",
    "        \n",
    "        # 1. Reconstruction Loss (MSE)\n",
    "        recon_loss = F.mse_loss(pred_coords, target_coords)\n",
    "        \n",
    "        # 2. KL Divergence (force Z to be Normal)\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        kl_loss /= B # Normalize by batch\n",
    "        \n",
    "        total_loss = recon_loss + (0.001 * kl_loss) # Weight KL term small\n",
    "        \n",
    "        self.log(\"train_loss\", total_loss)\n",
    "        return total_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "\n",
    "# ==========================================\n",
    "# Helper: Positional Encoding\n",
    "# ==========================================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, Seq_Len, Dim)\n",
    "        return x + self.pe[:x.size(1), :]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
